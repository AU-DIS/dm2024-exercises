{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "creative-harrison",
   "metadata": {},
   "source": [
    "# Hand In 3 - Frequent patterns\n",
    "\n",
    "Welcome to the handin on frequent patterns. \n",
    "This handin corresponds to the topics in Week 16--19 in the course.\n",
    "\n",
    "The handin IS \n",
    "* done in groups of two people\n",
    "* worth 10% of the grade\n",
    "\n",
    "For the handin, you will prepare a report in PDF format, by exporting the Jupyter notebook. \n",
    "Please submit\n",
    "1. The jupyter notebook file with your answers\n",
    "2. The PDF obtained by exporting the jupyter notebook\n",
    "\n",
    "**The grading system**: Tasks are assigned a number of points based on the difficulty and time to solve it. The sum of\n",
    "the number of points is **80**. For the maximum grade you need to get at least _65 points_. The minimum grade (02 in the Danish scale)\n",
    "requires **at least** 24 points, with at least 8 points on of the first three Parts (Part 1,2,3).\n",
    "Good luck!\n",
    "\n",
    "**The exercise types**: There are four different types of exercises\n",
    "1. <span style='color: green'>**\\[Compute by hand\\]**</span> means that you should provide NO code, but show the main steps to reach the result (not all). \n",
    "2. <span style='color: green'>**\\[Motivate\\]**</span> means to provide a short answer of 1-5 lines indicating the main reasoning, e.g., the PageRank of a complete graph is 1/n in all nodes as all nodes are symmetric and are connected one another.\n",
    "3. <span style='color: green'>**\\[Prove\\]**</span> means to provide a formal argument and NO code. \n",
    "4. <span style='color: green'>**\\[Implement\\]**</span> means to provide an implementation. Unless otherwise specified, you are allowed to use helper functions (e.g., ```np.mean```, ```itertools.combinations```, and so on). **However**, if the task is to implement an algorithm, by no means a call to a library that implements the same algorithm will be deemed as sufficient!\n",
    "\n",
    "**Q&A**\n",
    "\n",
    "Q: If the task is to implement a mean function, may I just call ```np.mean()```? \n",
    "<br>A: No.\n",
    "\n",
    "Q: If the task is to compare the mean of X and Y, may I use ```np.mean()``` to calculate the mean?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: If I have implemented a mean function in a previous task, but I am unsure of its correctness, may I use ```np.mean()``` in following task where mean is used as a helper function? \n",
    "<br>A: Yes.\n",
    "\n",
    "Q: May I use ```np.mean()``` to debug my implementation of mean?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Do I get 0 points for a task if I skip it?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Can I get partial points for a task I did partially correct?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Is it OK to skip a task if I do not need the points from it?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Should I inform a TA if I find an error?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Should I ask questions if I am confused?\n",
    "<br>A: Yes.\n",
    "\n",
    "\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utilities')\n",
    "#from load_data import load_dblp_citations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "designed-cornell",
   "metadata": {},
   "source": [
    "# Part 1: Subgraph mining (25 Points)\n",
    "In this part, we will work with subgraph mining algorithms. We will first solve some theory exercises and then implement two simple algorithms. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beneficial-softball",
   "metadata": {},
   "source": [
    "## Task 1.1 DFS codes (13 Points)\n",
    "\n",
    "### Task 1.1.1 (6 Points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> Find the canonical (i.e., minimal) DFS code for the graph below. Try to eliminate some codes without generating the complete search tree. *Hint*: you can eliminate a code if you can show that it will have a larger code than some other code (e.g., using label ordering, degree). \n",
    "\n",
    "<div>\n",
    "<img src=\"data/dfs-codes.png\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-surprise",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "confused-budget",
   "metadata": {},
   "source": [
    "### Task 1.1.2 (4 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> an extension to the DFS-code notation and the rules for the lexicographic ordering that handles the case of *directed* graphs. If that is not possible, state why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-rapid",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adjacent-correction",
   "metadata": {},
   "source": [
    "### Task 1.1.3 (3 Points)\n",
    " <span style='color: green'>**\\[Motivate\\]**</span> (no need for pseudocode) a suitable way to find the _maximum_ DFS-code from the rules for _minimum_ DFS-codes that you already know from the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-exhibit",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sexual-creation",
   "metadata": {},
   "source": [
    "## Task 1.2 Maximum Independent Set (12 Points)\n",
    "\n",
    "### Task 1.2.1 (6 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span>  Sketch a proof that the Maximum Independent Set (MIS) support is anti-monotone, i.e., the support of a pattern $P'$ is no larger than _any_ pattern $P$ included in $P'$ (that is, $P$ is a sub-pattern of $P'$). To guide you into the proof, start from a set of matchings of the pattern $P'$ which corresponds to an independent set of nodes $I'$ in the overlap graph $G'_{O}$, same for the set of nodes $I$ in the overlap graph $G_O$ of $P$. Observe (_Observation 1_) that the **all** the matchings $f'$ of $P'$ contain matchings $f$ of $P$. Also observe (_Observation 2_) that if you take two matchings $f_1'$ and $f_2'$ of $P'$ and the corresponding matchings $f_1$ and $f_2$ of $P$ overlap, so do the matchings $f_1'$ and $f_2'$. Given these two observation what can you deduce on the independent sets $I'$ of $G'_O$ and $I$ of $G_O$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-graduation",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "functioning-reynolds",
   "metadata": {},
   "source": [
    "### Task 1.2.2 (6 Points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> In this exercise, we will program a simplified version of the Maximum Indepent Set (MIS) support. Your exercise is to construct an algorithm that takes in input a pattern $P$ and the matches of the pattern in the graph $G$ and finds the Maximum Independent Set (MIS) support. Since finding the MIS is NP-hard your exercise is to implement a simple greedy approximation  algorithm. To test the code you can use the graph and code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mis_support(P, matches): \n",
    "    \"\"\"\n",
    "    Returns the MIS support of a pattern. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P:       The pattern represented as a networkx undirected graph object\n",
    "    matches: A list of subgraph isomorphic matches. Each match is a dictionary id_node_pattern -> id_node_graph\n",
    "    \"\"\"\n",
    "    mis = 0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import isomorphism\n",
    "\n",
    "# Example pattern\n",
    "P = nx.Graph()\n",
    "P.add_nodes_from([(1,{\"label\":\"A\"}), (2,{\"label\":\"B\"}), (3,{\"label\":\"C\"})])\n",
    "P.add_edges_from([(1,2),(2,3)])\n",
    "labels = nx.get_node_attributes(P, 'label') \n",
    "plt.figure(1)\n",
    "nx.draw(P,labels=labels)\n",
    "\n",
    "# Example graph\n",
    "G = nx.read_gml(\"data/graph.gml\", label='id')\n",
    "labels = nx.get_node_attributes(G, 'label') \n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(2)\n",
    "nx.draw(G,pos, labels=labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Find the matches of P in G\n",
    "nm = isomorphism.GraphMatcher(G,P,node_match=isomorphism.categorical_node_match(\"label\", \"A\"))\n",
    "matches = []\n",
    "for subgraph in nm.subgraph_monomorphisms_iter():\n",
    "    matches.append(subgraph)\n",
    "    print(subgraph)\n",
    "    \n",
    "print(\"The MIS support for pattern %s in G is: %f\" %(P.nodes, mis_support(P, matches)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRA CODE BLOCK HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-evolution",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "front-contact",
   "metadata": {},
   "source": [
    "# Part 2: Frequent itemsets (25 Points)\n",
    "We have learned the Apriori and FP-Growth algorithms for mining frequent itemsets. In this part, we will implement these algorithms and test them against each other. \n",
    "\n",
    "We will use the anonymized real-world `retail market basket` data from: http://fimi.ua.ac.be/data/.\n",
    "This data comes from an anonymous Belgian retail store, and was donated by Tom Brijs from Limburgs Universitair Centrum, Belgium. The original data contains 16,470 different items and 88,162 transactions. You may only work with the top-50 items in terms of occurrence frequency.\n",
    "_Hint:_ We have used this dataset before.\n",
    "\n",
    "The variable **retail_small** contains the top-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_market_basket\n",
    "\n",
    "\n",
    "def filter_transactions(T, k=50):\n",
    "    \"\"\"\n",
    "        Keep only the top k items in the transactions.\n",
    "        Remove transactions that become empty.\n",
    "    \"\"\"\n",
    "    # Count occurences of each item\n",
    "    counts = [0] * 16470\n",
    "    for t in T:\n",
    "        for i in t:\n",
    "            counts[i] += 1\n",
    "\n",
    "    # Sort and select top k\n",
    "    counts = np.array(counts)\n",
    "    order  = np.argsort(counts)[::-1] # reverse the sorted order\n",
    "\n",
    "    indexes_to_keep = order[:k]       # Keep the top k items\n",
    "    index_set = set(indexes_to_keep)  # Convert to python set for efficiency\n",
    "\n",
    "    # Filter transactions\n",
    "    T_new = [t_ for t_ in  [list(filter(lambda i: i in index_set, t)) for t in T]  if t_]\n",
    "    return T_new\n",
    "\n",
    "retail = load_market_basket()\n",
    "retail_small = filter_transactions(retail)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "incorrect-psychology",
   "metadata": {},
   "source": [
    "## Task 2.1 Association Rules (4 Points)\n",
    "Consider the following table\n",
    "\n",
    "| transaction ID \t| Items           \t|\n",
    "|----------------\t|-----------------\t|\n",
    "| 1              \t| Ape,Cat,Dog,Cow     \t|\n",
    "| 2              \t| Cat,Dog,Pig,Cow \t|\n",
    "| 3              \t| Dog,Bat,Pig,Cow \t|\n",
    "| 4              \t| Dog,Pig,Cow     \t|\n",
    "| 5              \t| Dog,Cow         \t|\n",
    "| 6              \t| Cat,Cow         \t|\n",
    "| 7              \t| Ape,Bat,Fox     \t|\n",
    "| 8              \t| Ape,Cow         \t|\n",
    "| 9              \t| Ape,Dog,Cow     \t|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acute-shade",
   "metadata": {},
   "source": [
    "### Task 2.1.1 (0.5 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> What is the count of the itemset {Dog,Pig,Cow} ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-account",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "strategic-adolescent",
   "metadata": {},
   "source": [
    "### Task 2.1.2 (0.5 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span>What is the support and confidence of the association rule {Dog,Pig}->Cow ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-kennedy",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "neither-seattle",
   "metadata": {},
   "source": [
    "### Task 2.1.3 (1.5 Point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> Consider the application of the Apriori algorithm to find all the frequent itemsets\n",
    "whose counts are at least 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-prime",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "humanitarian-walnut",
   "metadata": {},
   "source": [
    "### Task 2.1.4 (1.5 Point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> Find all the association rules with support at least 1/3 and confidence at least 1/2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-wright",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "voluntary-transformation",
   "metadata": {},
   "source": [
    "## Task 2.2 A Priori algorithm (9 Points)\n",
    "\n",
    "### Task 2.2.1(7 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Develop an implementation of the Apriori algorithm. You can look at your implementation from the exercises (note that this one is slightly different to simplify comparison with FP-Growth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_algorithm(T, min_support=10):\n",
    "    \"\"\"\n",
    "        Apriori algorithm for mining frequent itemsets and association rules. \n",
    "        This implementation should just find frequent itemsets, and ignore the rule generation.\n",
    "        Inputs:\n",
    "            T:               A list of lists, each inner list will contiain integer-item-ids. \n",
    "                             Example: T = [[1, 2, 5], [2, 3, 4], [1, 6]]\n",
    "            min_support:     int: The total number of occurences needed for an itemset to be considered frequent\n",
    "        \n",
    "        Outputs:\n",
    "            itemsets:        Dictionary of with keys as frequent itemset, and value as the total count of this itemset \n",
    "    \"\"\"\n",
    "    itemsets = dict()\n",
    "    ### TODO Your code here\n",
    "    \n",
    "    ### TODO Your code here\n",
    "    return itemsets\n",
    "\n",
    "def compute_candidates(prev_itemset):\n",
    "    Ck = set()\n",
    "    # Join step\n",
    "    for itemset in prev_itemset:\n",
    "        its1 = tuple(sorted(itemset))\n",
    "        for itemset2 in prev_itemset:\n",
    "            its2 = tuple(sorted(itemset2))\n",
    "            if its1[:-1] == its2[:-1]:\n",
    "                if its1[-1] < its2[-1]: Ck.add(its1 + its2[-1:])\n",
    "\n",
    "    # Pruning step\n",
    "    to_remove = set()\n",
    "    for c in Ck:\n",
    "        for subset in combinations(c, len(c)-1):\n",
    "            if not subset in prev_itemset:\n",
    "                to_remove.add(c)\n",
    "                break\n",
    "    for c in to_remove:\n",
    "        Ck.remove(c)\n",
    "    \n",
    "    return Ck"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unauthorized-essence",
   "metadata": {},
   "source": [
    "### Task 2.2.2 (2 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Run Apriori on the data-set (using the **retail** variable and not the small one). Try a few different values of min_support. </br>\n",
    "<span style='color: green'>**\\[Motivate\\]**</span>Roughly how large does min_support need to be before no itemsets of size 2 are found? (You don't need to find the excact value. Nearest 1000 is fine).\n",
    "\n",
    "Note that the dataset is reasonably large, so this **can take up a large amount of time depending on your value of min support and implementation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_algorithm(retail, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-department",
   "metadata": {},
   "source": [
    "******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adaptive-copying",
   "metadata": {},
   "source": [
    "## Task 2.3 FP-Growth (9 Points)\n",
    "\n",
    "### Task 2.3.1 (7 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Complete the implementation of FP-Growth below. You only need to implement growing the tree and building the header table. It is clearly marked where you need to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FP_Tree:\n",
    "    def __init__(self, T, min_support=10):\n",
    "        \"\"\"\n",
    "        Constructor for FP_Tree. Should correctly build an FP-Tree with header table.\n",
    "        Hint: I strongly advise you to implement the missing sections of the Node class before this one\n",
    "        \n",
    "        Inputs:\n",
    "            T:               A list of lists, each inner list will contiain integer-item-ids. \n",
    "                             Example: T = [[1, 2, 5], [2, 3, 4], [1, 6]]\n",
    "            min_support:     The total number of occurences needed to keep the itemset.\n",
    "        \"\"\"\n",
    "        self.min_support    = min_support\n",
    "        self.header_table   = {}\n",
    "        self.root           = Node(header_table = self.header_table)\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### Common functions for FP-tree and Conditional FP-tree\n",
    "    ### You do not need to modify the rest of this class\n",
    "    def generate_pattern(self, keys, support):\n",
    "        return tuple(keys + self.get_suffix()), support\n",
    "    \n",
    "    def get_suffix(self):\n",
    "        return []\n",
    "    \n",
    "    # This is the main function for generating frequent itemsets. You do not need to modify this,\n",
    "    # but I recommend reading and trying to understand it.\n",
    "    def mine_frequent_itemsets(self, res=None):\n",
    "        if res is None: res = []\n",
    "        \n",
    "        if self.root.is_single_path():\n",
    "            keys = list(self.header_table.keys())\n",
    "            key_idx = {k:i for i, k in enumerate(keys)}\n",
    "            counts = [self.header_table[k].count for k in keys]\n",
    "            \n",
    "            for key_pair in itertools.chain(*[itertools.combinations(keys, k) for k in range(1, len(keys)+1)]):\n",
    "                support = min([counts[key_idx[k]] for k in key_pair])\n",
    "                if support >= self.min_support: \n",
    "                    res.append(self.generate_pattern(list(key_pair), support))\n",
    "         \n",
    "        else: # Not single path\n",
    "            for key, node in self.header_table.items():\n",
    "                support = node.support()\n",
    "                \n",
    "                if support >= self.min_support:\n",
    "                    res.append( self.generate_pattern([key], support) )\n",
    "                \n",
    "                basis = []\n",
    "                while node is not None:\n",
    "                    curr_node = node\n",
    "                    node = node.nodelink\n",
    "                    \n",
    "                    if curr_node.parent is None:  continue\n",
    "                        \n",
    "                    path = curr_node.path(limit=curr_node.count)[:-1]\n",
    "                    if len(path) == 0:  continue\n",
    "                        \n",
    "                    basis.append( path )\n",
    "                    \n",
    "                if len(basis) == 0: continue\n",
    "                    \n",
    "                conditional_tree = Conditional_FP_Tree(self.min_support, [key] + self.get_suffix(), basis)\n",
    "                if conditional_tree.root is None: continue\n",
    "                    \n",
    "                conditional_tree.mine_frequent_itemsets(res=res)\n",
    "        return res\n",
    "\n",
    "\n",
    "# You don't need to modify anything in this class\n",
    "class Conditional_FP_Tree(FP_Tree):\n",
    "    def __init__(self, min_support, suffix, basis): \n",
    "        self.min_support    = min_support\n",
    "        self.suffix         = suffix\n",
    "        self.header_table   = {} # This will hold all unique items\n",
    "        \n",
    "        self.root           = Node(header_table=self.header_table)\n",
    "        \n",
    "        self.build_tree(basis)\n",
    "        # self.root           = prune(self.root, min_support)\n",
    "        if self.root is None: print(\"WARNING: root is empty after pruning\")\n",
    "        \n",
    "    def build_tree(self, basis):\n",
    "        for b in basis:\n",
    "            count = b[0][1]\n",
    "            path = list(map(lambda x: x[0], b))\n",
    "            for i in range(count):\n",
    "                self.root.add_path(path)\n",
    "    \n",
    "    def get_suffix(self):\n",
    "        return self.suffix\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, header_table, value=None, parent=None, path=None):\n",
    "        \"\"\"\n",
    "        Constructor for Node class, which is used for the FP-Tree. \n",
    "        Inputs:\n",
    "            header_table:    Dict. Should be same dict for all nodes in the tree\n",
    "            value:           Integer id of the item the node represents\n",
    "            parent:          Parent Node. None if root node\n",
    "            path:            List of node values for a path that should start in this node.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.children     = {}\n",
    "        self.header_table = header_table \n",
    "        self.nodelink     = None\n",
    "        self.value        = None\n",
    "        self.parent       = None\n",
    "        self.count        = 0\n",
    "        \n",
    "        if value is not None: # Only root node should have None as value\n",
    "            self.value          = value\n",
    "            self.parent         = parent\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "        \n",
    "        if path is not None: \n",
    "            self.add_path(path)\n",
    "            \n",
    "    \n",
    "    def add_path(self, path):\n",
    "        \"\"\"\n",
    "        Function for adding a path to tree. \n",
    "        Should follow an existing path and increment count while such a path exists. \n",
    "        If no path exists (or only partial path exists), this function should create or complete such a path\n",
    "        Hint: Recursion might be helpful.\n",
    "        Inputs:\n",
    "            path:            A list node values. \n",
    "                             Example: path = [1, 2, 5]\n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE\n",
    "        \n",
    "        ### YOUR CODE\n",
    "    \n",
    "    \n",
    "    # Functions for frequent items-sets and rule mining below. You do not need to modify these\n",
    "    def is_single_path(self):\n",
    "        if   len(self.children) == 0: return True \n",
    "        elif len(self.children) >  1: return False\n",
    "        else:  # len == 1\n",
    "            key = next((k for k in self.children.keys()))\n",
    "            return self.children[key].is_single_path()\n",
    "    \n",
    "    def support(self, verbose=False):\n",
    "        if verbose: print(\"Counting support, this value is \", self.value, \" with count \", self.count, \" and parent \", self.parent.value)\n",
    "            \n",
    "        if self.nodelink is not None: return self.count + self.nodelink.support(verbose)\n",
    "        else:                         return self.count\n",
    "    \n",
    "    def path(self, limit=-1):\n",
    "        if self.value is None: \n",
    "            return []\n",
    "        else:                  \n",
    "            count = self.count if limit == -1 else min(self.count, limit)\n",
    "            return self.parent.path(limit=limit) + [(self.value, count)]\n",
    "    \n",
    "    def print(self, indent=\"\", spacing=\"----|-\"):\n",
    "        print(indent + str(self.value) + \":\" + str(self.count))\n",
    "        for v in self.children.values():\n",
    "            v.print(indent=indent + spacing)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR TEST CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adjustable-lawrence",
   "metadata": {},
   "source": [
    "### Task 2.3.2 (2 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Run FP-Growth on the data-set (using the **retail** variable and not the small one). Try a few different values of min_support. </br>\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> Roughly how large does min_support need to be before all itemsets of size 1 and 2 are found but no itemsets of size 3? (You don't need to find the excact value. Nearest 1000 is fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "authorized-watts",
   "metadata": {},
   "source": [
    "## Task 2.4 Comparing A priori and FP-Growth (3 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> Run the given experiment and show to what extent FP-Growth has an advantage. Comment on the results. What do you see? What do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for testing the runtime of your algorithms. \n",
    "# WARNING: This will take a reasonably long time to run.\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "    \n",
    "def sample(n=200, alphabet_size=5):\n",
    "    candidates  = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])[:alphabet_size]\n",
    "    m = candidates.shape[0]\n",
    "    \n",
    "    T = []\n",
    "    for i in range(n):\n",
    "        size = int(np.random.rand() * (m)) + 1\n",
    "        T.append(list(candidates[np.random.permutation(m)[:size]]))\n",
    "        \n",
    "    return T\n",
    "\n",
    "def test():\n",
    "    # If you want to test it quickly, you can modify \"transaction_lengths\" and \"alphabet_sizes\" temporarily. \n",
    "    # This will give you errors in the plotting (next code cell) though.\n",
    "    # Make sure you use the original values for \"transaction_lengths\" and \"alphabet_sizes\" for your final version.\n",
    "    transaction_lengths = [2**i for i in range(4, 11)]\n",
    "    alphabet_sizes      = [3, 6, 9, 12] \n",
    "    \n",
    "    min_support = 10\n",
    "    repeats     = 10\n",
    "    \n",
    "    stop = False\n",
    "    results = np.zeros((len(transaction_lengths), len(alphabet_sizes), 2))\n",
    "    stderrs = np.zeros((len(transaction_lengths), len(alphabet_sizes), 2))\n",
    "    \n",
    "#     print(results.shape)\n",
    "    \n",
    "    for i, n in enumerate(transaction_lengths):\n",
    "        for j, a in enumerate(alphabet_sizes):\n",
    "            print(\" - - \" * 4, \"n=%d,a=%d\" % (n, a), \" - - \" * 4)\n",
    "            times = []\n",
    "            for _ in range(repeats):\n",
    "                T = sample(n, a)\n",
    "\n",
    "                t0 = time.time()\n",
    "                tree = FP_Tree(T, min_support=min_support)\n",
    "                frequent_itemsets = tree.mine_frequent_itemsets()\n",
    "                t1 = time.time() - t0\n",
    "\n",
    "                i1 = {tuple(sorted(list(k))): v for k, v in frequent_itemsets}\n",
    "\n",
    "                t0 = time.time()\n",
    "                itemsets = apriori_algorithm(T, min_support=min_support)\n",
    "                t2 = time.time() - t0\n",
    "\n",
    "                i2 = {}\n",
    "                for V in itemsets.values():\n",
    "                    for k, v in V.items():\n",
    "                        i2[tuple(sorted(list(k)))] = v\n",
    "\n",
    "                assert len(i1) == len(i2)\n",
    "                for k in i1.keys():\n",
    "                    assert i1[k] == i2[k]\n",
    "\n",
    "                times.append([t1, t2])\n",
    "\n",
    "            results[i, j] = np.mean(times, axis=0)\n",
    "            stderrs[i, j] = np.std(times, axis=0)\n",
    "            print(np.mean(times, axis=0), \"+-\", np.std(times, axis=0), \"\\n\")\n",
    "            \n",
    "    np.save('itemsets_runningtimes', results)  # Results are saved to avoid having to run it again if plot code needs changing\n",
    "    np.save('itemsets_stderr', stderrs)\n",
    "    \n",
    "    return results, stderrs\n",
    "        \n",
    "results, stderrs = test()     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = np.load('itemsets_runningtimes.npy')\n",
    "stderrs = np.load('itemsets_stderr.npy')\n",
    "\n",
    "# Plotting \n",
    "transaction_lengths = [2**i for i in range(4, 11)]\n",
    "alphabet_sizes      = [3, 6, 9, 12] \n",
    "\n",
    "n, a, _ = results.shape\n",
    "res_to_plot = np.transpose(results, (1, 0, 2))\n",
    "err_to_plot = np.transpose(stderrs, (1, 0, 2))\n",
    "\n",
    "fig, ax = plt.subplots(1, a, figsize=(4*a, 4))\n",
    "for i, (res, err) in enumerate(zip(res_to_plot, err_to_plot)):\n",
    "    ax[i].plot(transaction_lengths, res[:,0], label='FP-Tree', color='C1')\n",
    "    ax[i].fill_between(transaction_lengths, res[:,0] - err[:,0], res[:,0] + err[:,0], alpha=0.3, linewidth=0 , color='C1')\n",
    "    \n",
    "    x = transaction_lengths[-1]\n",
    "    ax[i].set_xlim((2**4, 2**11))\n",
    "    ax[i].annotate(text='', xy=(x, res[-1,0]), xytext=(x,res[-1,1]), arrowprops=dict(arrowstyle='|-|'))\n",
    "    ax[i].annotate(text='%.1f $\\\\times$'%(res[-1,1]/res[-1,0]), xy=(x-24,  (res[-1,1] / 2 + res[-1,0]/2)), horizontalalignment='right')\n",
    "    \n",
    "    ax[i].plot(transaction_lengths, res[:,1], label='Apriori', color='C2')\n",
    "    ax[i].fill_between(transaction_lengths, res[:,1] - err[:,1], res[:,1] + err[:,1], alpha=0.3, linewidth=0 , color='C2')\n",
    "    \n",
    "    ax[i].set_title(\"Alphabet size: %d\" % alphabet_sizes[i])\n",
    "    ax[i].set_xscale('log', base=2)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('Number of transactions')\n",
    "    ax[i].set_ylabel('Seconds')\n",
    "\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-vehicle",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aerial-steps",
   "metadata": {},
   "source": [
    "# Part 3: Sequence Segmentation and LSH (30 Points)\n",
    "The Dynamic Programming algorithm for optimally segmenting a sequence $S$ of length $n$ \n",
    "into $B$ segments, that we have introduced, is expressed by the following recursive equation:\n",
    "\n",
    "$$\n",
    "E(i, b) = \\min_{j < i}\\left[ E(j, b-1) + Err(j+1, i)\\right]\n",
    "$$\n",
    "\n",
    "where $Err(j+1, i)$ is the error of a segment that contains items from $j+1$ to $i$.\n",
    "\n",
    "In this part, you will have to answer some questions on this.\n",
    "\n",
    "**Note:** \n",
    "For those of you, who are not used to analyzing algorithms: by time-complexity and space-complexity, \n",
    "we refer to the theoretical computation time and memory usage, respectively, as a function of the problem size, i.e., as a \n",
    "function of $n$ and $B$ in Problem 3. We use [Big O notation](https://en.wikipedia.org/wiki/Big_O_notation)\n",
    "to specify this. You should **not** infer it by implementing it in practice ;-) \n",
    "Again, when in doubt, ask on Discord, Blackboard or shoot Jon an email. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "specified-treasure",
   "metadata": {},
   "source": [
    "## Task 3.1 Sequence segmentation (20 Points)\n",
    "\n",
    "************\n",
    "<span style='color: red'>**These questions are hard. First complete the rest of the exercises and then come back to solve 3.1.**</span>\n",
    "************\n",
    "\n",
    "\n",
    "### Task 3.1.1\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> what is the default space-complexity of this algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-plaza",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-schedule",
   "metadata": {},
   "source": [
    "### Task 3.1.2 \n",
    "<span style='color: green'>**\\[Motivate\\]**</span> what happens if we are willing to recompute some tabulated results. Can we then reduce the default space-complexity? _Exactly how_? What is the space-complexity then?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-threat",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-cutting",
   "metadata": {},
   "source": [
    "### Task 3.1.3 \n",
    "<span style='color: green'>**\\[Motivate\\]**</span> what is the cost of using the space-efficiency technique described in Task 3.1.2 in terms of time-complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-block",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-purchase",
   "metadata": {},
   "source": [
    "### Task 3.1.4 \n",
    "For the sub-problem of segmenting the $i$-prefix of sequence $S$ into $b$ segments, consider \n",
    "    the segment $M(i, b)$ that contains (if such segment exists) the middle item of \n",
    "    index $\\lfloor \\frac{n}{2} \\rfloor$. The boundaries of $M(i, b)$ can be detected and tabulated \n",
    "    along with each $E(i, b)$ solution. \n",
    "\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> a method that reduces the time-complexity burden identified in Task 3.1.3, based on the above observarion. \n",
    "    _(hint: use [divide-and-conquer](https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm))_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-antenna",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-palmer",
   "metadata": {},
   "source": [
    "### Task 3.1.5 \n",
    "<span style='color: green'>**\\[Motivate\\]**</span> what is the time complexity when using the technique proposed in Task 3.1.4?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-opinion",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-translator",
   "metadata": {},
   "source": [
    "## Task 3.2 Min Hashing (6 Points)\n",
    "\n",
    "In this exercise we will see the **One-pass implementation** of the MinHash signatures.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-latino",
   "metadata": {},
   "source": [
    "### Task 3.2.1 \n",
    "<span style='color: green'>**\\[Implement\\]**</span> Implement the One-pass algorithm for the MinHash Signatures (and the jaccard simmilarity matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C is the Input Matrix (Shingles x Documents)\n",
    "#J_sim is a jaccard similarity matrix (Documents x Documents)\n",
    "def jaccard_simmilarity_matrix(C):\n",
    "    J_sim = None\n",
    "    ### YOUR CODE STARTS HERE\n",
    "    \n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return J_sim\n",
    "\n",
    "#C is the Input Matrix (Shingles x Documents)\n",
    "#no_of_permutations is the how many permutations we will use\n",
    "#C_new is the Output Matrix (no_of_permutations x Documents)\n",
    "def one_pass_hashing(C, no_of_permutations):\n",
    "    C_new = None\n",
    "    ### YOUR CODE STARTS HERE\n",
    "    \n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return C_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-individual",
   "metadata": {},
   "source": [
    "### Task 3.2.2 \n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> For the matrix below run your implementation for different number of permutations in the range [1,4] and report: a) the Output Matrix C_new and  b) the jaccard similarity matrix of C_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-siemens",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span> Suppose we have 4 documents named as X,Y,Z and W and their signatures are given by the input matrix $C$ as:\n",
    "$$\\begin{matrix} X & Y & Z & W \\\\1 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 1\\\\0 & 0 & 1 & 0 \\end{matrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-letter",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-confusion",
   "metadata": {},
   "source": [
    "### Task 3.2.3 \n",
    "Suppose we have two hash functions (permutations) as <br> $h_1(x) = (x + 1) mod 5$ and $h_2(x)=(3x + 1) mod 5$ \n",
    "<span style='color: green'>**\\[Motivate\\]**</span> and <span style='color: green'>**\\[Compute by Hand\\]**</span> the steps of the one-pass implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-cemetery",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-alliance",
   "metadata": {},
   "source": [
    "## Task 3.3 Locality Sensitive Hashing (4 points)\n",
    "\n",
    "### Task 3.3.1 \n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> code that evaluate the S-curve $1-(1-s^r)^b$ for $s\\in [0,1]$ for the following values of $r$ and $b$ \n",
    "1. $r = 3$ and $b = 10$\n",
    "2. $r = 6$ and $b = 20$\n",
    "3. $r = 5$ and $b = 50$\n",
    "\n",
    "You can use, or modify, the helper plotting code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "x = np.linspace(0.01,0.99,100)\n",
    "y = s_curve(5,50)(x)\n",
    "\n",
    "def plot_function(x,y): \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    # plot the function\n",
    "    plt.plot(x,y, 'r')\n",
    "\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "plot_function(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-rebel",
   "metadata": {},
   "source": [
    "### Task 3.3.2 \n",
    "\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> For each of the (r,b) pairs in Task 3.2.1, compute the value of $s$ for which the value of $1-(1-s^r)^b$ is exactly 1/2. How does this value compare with the estimate of $(1/b)^{1/r}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-austin",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
