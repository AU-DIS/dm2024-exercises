{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "overall-spider",
   "metadata": {},
   "source": [
    "# Data Mining - Handin 1 - Clustering \n",
    "Welcome to the handin on clustering algorithms and outlier detection. \n",
    "This handin corresponds to the topics in Week 5--9 in the course.\n",
    "\n",
    "The handin is \n",
    "* done in the chosen handin groups\n",
    "* worth 10% of the final grade\n",
    "\n",
    "For the handin, you will prepare a report in PDF format, by exporting the Jupyter notebook. \n",
    "Please submit\n",
    "1. The jupyter notebook file with your answers\n",
    "2. The PDF obtained by exporting the jupyter notebook\n",
    "\n",
    "**The grading system**: Tasks are assigned a number of points based on the difficulty and time to solve it. The sum of the number of points is 100. For the maximum grade you need to get at least _80 points_. The minimum grade (02 in the Danish scale)\n",
    "requires **at least** 30 points, with at least 8 points from the first three Parts (Part 1,2,3) and 6 points in the last part (Part 4).\n",
    "\n",
    "**The exercise types**: There are four different types of exercises\n",
    "1. <span style='color: green'>**\\[Compute by hand\\]**</span> means that you should provide NO code, but show the main steps to reach the result (not all). \n",
    "2. <span style='color: green'>**\\[Motivate\\]**</span> means to provide a short answer of 1-5 lines indicating the main reasoning, e.g., the PageRank of a complete graph is 1/n in all nodes as all nodes are symmetric and are connected one another.\n",
    "3. <span style='color: green'>**\\[Prove\\]**</span> means to provide a formal argument and NO code. \n",
    "4. <span style='color: green'>**\\[Implement\\]**</span> means to provide an implementation. Unless otherwise specified, you are allowed to use helper functions (e.g., ```np.mean```, ```itertools.combinations```, and so on). **However**, if the task is to implement an algorithm, by no means a call to a library that implements the same algorithm will be deemed as sufficient!\n",
    "\n",
    "**Q&A**\n",
    "\n",
    "Q: If the task is to implement a mean function, may I just call ```np.mean()```? \n",
    "<br>A: No.\n",
    "\n",
    "Q: If the task is to compare the mean of X and Y, may I use ```np.mean()``` to calculate the mean?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: If I have implemented a mean function in a previous task, but I am unsure of its correctness, may I use ```np.mean()``` in following task where mean is used as a helper function? \n",
    "<br>A: Yes.\n",
    "\n",
    "Q: May I use ```np.mean()``` to debug my implementation of mean?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Do I get 0 points for a task if I skip it?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Can I get partial points for a task I did partially correct?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Is it OK to skip a task if I do not need the points from it?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Should I inform a TA if I find an error?\n",
    "<br>A: Yes.\n",
    "\n",
    "Q: Should I ask questions if I am confused?\n",
    "<br>A: Yes.\n",
    "\n",
    "\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT TOUCH\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 132419\n",
    "## DO NOT TOUCH\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./data/dota2.csv\")\n",
    "color_map = {'Intelligence':'Blue', 'Universal':'Yellow', 'Agility':'Green', 'Strength':'Red'}\n",
    "toy = df[df['A'].isin(['Agility', 'Strength'])].sample(n=10, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-regression",
   "metadata": {},
   "source": [
    "# Part 1 Intro Excercises\n",
    "\n",
    "## Task 1.1 K-Means and DBScan\n",
    "\n",
    "### Task 1.1.1 (4 points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> the cluster assignments _for the dataset below_ using k-means and $k = 2$, with initial centroids being (25, 12) and (21,20)\n",
    "\n",
    "<font color='red'>To evaluate (i.e., only to control the correctness and not to solve the exercise) your results you can use **sklearn.cluster.KMeans**.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = 'STR'\n",
    "last = 'AGI'\n",
    "\n",
    "X_kmeans = toy[[first, last]]\n",
    "\n",
    "plt.scatter(X_kmeans[first], X_kmeans[last], alpha=0.8, c=toy['A'].map(color_map))\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-matter",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-somerset",
   "metadata": {},
   "source": [
    "### Task 1.1.2 (2 point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> <br>\n",
    "A) Show two examples with two different initial cluster assignments that lead to a different result. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-vertex",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-chicago",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span> <br>\n",
    "B) How do you explain the difference between the two cluster assignments in point A)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-office",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-management",
   "metadata": {},
   "source": [
    "### Task 1.1.3 (4 points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> the dendrogram for the dataset of Task 1.1.1. using **average-link**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-template",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-benjamin",
   "metadata": {},
   "source": [
    "### Task 1.1.4 (2 points)\n",
    "A) <span style='color: green'>**\\[Compute by hand\\]**</span> the density-based clustering DBSCAN for the dataset of Task 1.1.1 using $\\epsilon=3.5$ and $MinPts=2$. Present at least 2 iterations of the algorithm.<br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-emperor",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-briefs",
   "metadata": {},
   "source": [
    "\n",
    "B) <span style='color: green'>**\\[Motivate\\]**</span> the difference between the clusters obtained with DBSCAN and those obtained with KMeans in Task 1.1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-programming",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-fields",
   "metadata": {},
   "source": [
    "## Task 1.2 Elliptic data set (2 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> <br> \n",
    "After looking at the dataset _below_, you want to detect the red outlier point, assuming you know that it is an outlier. \n",
    "\n",
    "Which approach would be the most obvious to find the red outlier? Please (1) check the box and (2) motivate your answer below:\n",
    "- [ ] Distance based approach (with parameteres $\\pi=0.5$, $\\epsilon=2$ and euclidean distance)\n",
    "- [ ] Angle based approach\n",
    "- [ ] Depth based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_new = np.array([[1.0, 2.0], # Red \n",
    "                [1., 1.0],\n",
    "                [0.5, 0.5],\n",
    "                [1, 0.5],\n",
    "                [0.5, 1],\n",
    "                [0.75, 0.75]\n",
    "                 ])\n",
    "\n",
    "plt.scatter(D_new[:, 0], D_new[:, 1], alpha=0.8, c = ['red' if i == 0 else 'blue' for i in range(len(D_new))])\n",
    "plt.axis([0, 2, 0,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-tuesday",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-extraction",
   "metadata": {},
   "source": [
    "## Task 1.3 Theoretical questions\n",
    "### Task 1.3.1 Triangle inequality (2 points)\n",
    "<span style='color: green'>**\\[Prove\\]**</span> 1. You are given a measure $d(x,y) = |x-y|$, prove that the measure is a metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-column",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbd657",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Prove\\]**</span> 2. If $d(p_1,p_2)\\leq\\frac{d(p_2,p_3)}{2}$, then $d(p_1,p_2)\\leq(p_1,p_3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c9cdc",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bf551",
   "metadata": {},
   "source": [
    "### Task 1.3.2 Kernel trick (9 points)\n",
    "<span style='color: green'>**\\[Motivation\\]**</span> A) What is a positive-definite kernel $K(x,x')$ of two vectors $x,x'\\in\\mathbb{R}^n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0696e0",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249d778",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span> B) Please explain briefly what is the kernel trick method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0ba08",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe260d",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Prove\\]**</span> C)\n",
    "Let two positive-definite kernels $K_1(x,x')$ and $K_2(x,x')$.  <br> Show that functions $K_1(x,x')+K_2(x,x')$ and $K_1(x,x')K_2(x,x')$ are also positive-definite kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b07b7",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94954d",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Prove\\]**</span> D) Prove that $K(x,x')=e^{2 ln(x^{\\top}x')-(x-x')^{\\top}(x-x')}$ is a positive-definite kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f812c",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-artwork",
   "metadata": {},
   "source": [
    "# Part 2 Exploratory data analysis\n",
    "In this section, you will perform preliminary analysis on your data. These preliminary analysis are useful to understand how the data behaves, before running complex algorithms.<br>\n",
    "\n",
    "This dataset is about dota2 heroes check ```datatainfo.md``` for more infomation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = df\n",
    "data_np = toy.to_numpy()\n",
    "headers = ['HERO','A','STR','STR+','STR30','AGI','AGI+','AGI30','INT','INT+','INT30','T','T+','T30','MS','AR','DMG_MIN','DMG_MAX','RG','AS','BAT','ATK_PT','ATK_BS','VS-D','VS-N','TR','COL','HP/S','MP/S','Complexity','Legs','Release','Artifact']\n",
    "X = data_np[:,2:]\n",
    "y = data_np[:,1]\n",
    "rows, cols = np.shape(X)\n",
    "toy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-ottawa",
   "metadata": {},
   "source": [
    "## Task 2.1 Correlation matrix\n",
    "### Task 2.1.1 (5 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span> in the code-box below the **correlation matrix** (not covariance matrix) among all the attributes. <br>\n",
    "<font color='red'>To CHECK your results you can use **numpy.corrcoef**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(X):\n",
    "    corr = None\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE \n",
    "    return corr\n",
    "    \n",
    "X = data_np\n",
    "Corr = correlation_matrix(X)\n",
    "plt.matshow(Corr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-volume",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "B) By observing the  **correlation matrix** in A), which pair(s) of different features has the highest correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-silver",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-senator",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "C) What does it mean that two features are highly correlated? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-breath",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-springfield",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "D) Based on the features of the data in Part 2 and your answer in C), did you expect the observation of B)? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-weekly",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-content",
   "metadata": {},
   "source": [
    "### Task 2.1.2 (1 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Plot the correlation matrix running the code below. (You may need to zoom on it)\n",
    "What is the relationship between the correlation matrix and the covariance matrix? (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "- [ ] The correlation matrix contains the unnormalized covariance values\n",
    "- [ ] The correlation matrix contains the normalized covariance values\n",
    "- [ ] The covariance matrix contains the variance of the correlation\n",
    "\n",
    "<font color='red'>Do NOT just choose an answer. Please clarify WHY this is the correct answer.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot = df.drop(['HERO','A'],axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(df_to_plot.corr(),annot=True,linewidths=1, cmap=\"YlGnBu\", annot_kws={\"fontsize\":10}, vmax=1, ax=ax)\n",
    "plt.title('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-behalf",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-shelter",
   "metadata": {},
   "source": [
    "### Task 2.1.3 (3 points)\n",
    "\n",
    "In this task, we reason about the covariance matrices.\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> code for normalizing the features of the dota2 dataset using (1) standard score normalization and (2) range normalization. Finally, (3) plot the **covariance** matrices for\n",
    "1. The unnormalized data\n",
    "2. The [standard score normalized features](https://en.wikipedia.org/wiki/Standard_score)\n",
    "3. The range (min-max) normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = data_np\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-decision",
   "metadata": {},
   "source": [
    "### Task 2.1.4 (3 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> how the covariance matrix changes with different normalization schemes and reason on why such behaviour appears.\n",
    "You should notice some differences. (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "\n",
    "\n",
    "- [ ] Range normalization preserves the variance. Therefore, features are directly comparable within the matrix.\n",
    "- [ ] Standard score normalization preserves the variance. Therefore, features are directly comparable within the matrix.\n",
    "- [ ] Both methods normalize in such a way, that it makes sense to compare the different covariance values to each other within the matrix. \n",
    "- [ ] None of the methods normalize in such a way that it makes sense to compare the different covariance values to each other.\n",
    "\n",
    "<font color='red'>Do NOT just choose an answer. Please clarify WHY this is the correct answer.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-adapter",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-entry",
   "metadata": {},
   "source": [
    "## Task 2.2 Normal distribution\n",
    "### Task 2.2.1 (6 points)\n",
    "Sometimes it is convenient to know whether a variable is close to a normal distribution.\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a method norm_dist that: <br>\n",
    "    \n",
    "1) **Inputs**: \n",
    "    * the number of buckets $b$ \n",
    "    * a vector $x$ of values \n",
    "2) First, compute the histogram of a Gaussian variable with mean $\\mu$ corresponding to the sample mean of $x$ and $\\sigma^2$ corresponding to the sample variance of $x$. Second, calculate the histogram of $x$ using $b$ buckets. \n",
    "3) **Output**: the sum of the absolute differences of the buckets between the two histograms computed in 2). The sum of the differences is computed as \n",
    "$$\\sum_{i=1}^b |H_X(i) - H_{\\mathcal{N}}(i)|$$ \n",
    "where $H_X(i)$ is the i-th bucket of the histogram of $x$ and $H_\\mathcal{N}(i)$ is the i-th bucket of the hisotgram obtained from the normal distribution $\\mathcal{N}(\\mu,\\sigma^2)$. \n",
    "\n",
    "<font color='red'>You can use the norm function from Scipy to get the normal distribution to subtract from.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "## Our data comes from the variable X\n",
    "X = data_np\n",
    "def norm_dist(x, b): \n",
    "    dist = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-mission",
   "metadata": {},
   "source": [
    "### Task 2.2.2 (6 point)\n",
    "A) <span style='color: green'>**\\[Motivate\\]**</span> which drawbacks the method in Task 2.2.1 has. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-sharp",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-blowing",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> whether the method in Task 2.2.1  is robust to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-blade",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-crown",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "C) Run your code on each columns of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-female",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "D) What is the column with the largest distance? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-workplace",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-delay",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "E) Do the features follow a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-match",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-cyprus",
   "metadata": {},
   "source": [
    "### Task 2.2.3 (1 points)\n",
    "\n",
    "Now look at the method below. This is called a Quantile-Quantile [Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot). \n",
    "\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> why this method is more robust than the one we proposed in Task 2.2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-battery",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import gridspec\n",
    "\n",
    "plt.tight_layout()\n",
    "_, n = X.shape\n",
    "print(headers, X.shape)\n",
    "fig = plt.figure(constrained_layout=True, figsize=(8, 50))\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=(n-1), figure=fig)\n",
    "for i in np.arange(2,n):\n",
    "    x = toy[headers[i]]\n",
    "    r = i-1\n",
    "    qq = fig.add_subplot(spec[r, 1]) \n",
    "    stats.probplot(x, plot=qq)\n",
    "    h = fig.add_subplot(spec[r, 0])\n",
    "    h.set_title(headers[i])\n",
    "    h.hist(x, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-harbor",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "collaborative-kinase",
   "metadata": {},
   "source": [
    "# Part 3 Cluster Analysis\n",
    "In this section, you will perform cluster analysis of the dataset in Part 2 and modify clustering algorithms to achieve better results. \n",
    "\n",
    "## Task 3.1\n",
    "\n",
    "### Task 3.1.1 (6 points)\n",
    "A)  <span style='color: green'>**\\[Implement\\]**</span> and plot the **silhouette coefficient** to detect the number of clusters $k$. \n",
    "\n",
    "<font color='red'>You can use the KMeans implementation from scikit-learn.</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = df[df['A'].isin(['Universal', 'Intelligence'])]\n",
    "first = \"T+\"\n",
    "second = \"INT+\"\n",
    "X = toy[[first, second]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = toy[[first, second]].to_numpy()\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-bubble",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> your choice of clusters $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-pharmacy",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-mortgage",
   "metadata": {},
   "source": [
    "### Task 3.1.2 (1 points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "Run k-means on the dataset X, with the number of clusters detected in the previous exercise.\n",
    "\n",
    "<font color='red'>You can use the KMeans implementation from scikit-learn.</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = toy[[first, second]].to_numpy()\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-power",
   "metadata": {},
   "source": [
    "### Task 3.1.3 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Kernel K-means and the Gaussian Kernel. \n",
    "\n",
    "The Gaussian kernel is defined as in the following equation:\n",
    "\n",
    "$$\n",
    "K\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right)=\\exp \\left(-\\frac{\\left\\|\\mathbf{x}_{i}-\\mathbf{x}_{j}\\right\\|^{2}}{2 \\sigma^{2}}\\right)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = df[df['A'].isin(['Strength', 'Intelligence', 'Universal'])]\n",
    "first = \"STR30\"\n",
    "second = \"T+\"\n",
    "init=[[-1,-1],[1,2]]\n",
    "\n",
    "X = toy[[first, second]].to_numpy()\n",
    "\n",
    "# Data normalization\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=0.2): \n",
    "    k = 0 \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return k\n",
    "\n",
    "\n",
    "def kernel_kmeans(X, n_clusters, kernel=gaussian_kernel, init=[[-1,-1],[1,2]], iters=100, error=0): \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return clusters\n",
    "\n",
    "scaler = StandardScaler().fit(X_norm)\n",
    "X_scaled = scaler.transform(X_norm)\n",
    "clusters = kernel_kmeans(X_scaled, SOME_AMOUNT_OF_CLUSTERS)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e186498",
   "metadata": {},
   "source": [
    "### Task 3.1.4 (1 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> Run both kmeans and kernel K-means on data. (with a given init)\n",
    "which method is better at isolating universal classified heroes and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a47ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init=[[-1,-1],[1,2]]\n",
    "kmeans = KMeans(n_clusters=2,init=init).fit(X_norm)\n",
    "plt.scatter(X_norm[:, 0], X_norm[:, 1], alpha=0.8, c=kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4083975",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kernel_kmeans(X_norm, 2, init=init)\n",
    "plt.scatter(X_norm[:, 0], X_norm[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ea9ec",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "transparent-junction",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3.2 Clustering quality\n",
    "\n",
    "### Task 3.2.1 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> **Conditional Entropy (CE)** as a measure for clustering quality.\n",
    "\n",
    "Entropy for a clustering is $H(C) = - \\sum_{i=1}^{k}{p_{C_i} \\log {p_{C_i}}}$.\n",
    "\n",
    "The **Conditional Entropy** of $T$ **given** $C$ is given by: \n",
    "$$\\text{CE}(T|C)=-\\sum\\limits^{|C|}_{i=1}\\sum\\limits^{|T|}_{j=1}\\frac{n_{ij}}{n}\\log\\frac{n_{ij}}{n_i}$$\n",
    "where $n_{i}$ is the total number of points in cluster $C_i$ and $n_{ij}$ is the number of common points between clusters $C_i$ and $T_j$\n",
    "\n",
    "\n",
    "**Hint**: First implement **Entropy** and then **Conditional Entropy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(C):\n",
    "    # Let C be a list of clusters\n",
    "    entropy = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def CE(C1, C2):\n",
    "    ce = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return ce"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sized-opportunity",
   "metadata": {},
   "source": [
    "### Task 3.2.2 (3 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span>\n",
    "Print the Conditional Entropy (implementation from the Task 3.2.1) among the class labels $y$ and the clusters you found with k-means in Task 3.1.1. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-pitch",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "toy = df[df['A'].isin(['Universal', 'Intelligence'])]\n",
    "first = \"T+\"\n",
    "second = \"INT+\"\n",
    "X = toy[[first, second]].to_numpy()\n",
    "###YOUR CODE HERE\n",
    "\n",
    "\n",
    "###YOUR CODE HERE\n",
    "class_labels = np.array(toy[\"A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-soundtrack",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "A) Reason about the measure, is the measure influenced by the size of the clusters?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-convert",
   "metadata": {},
   "source": [
    "******************* \n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-police",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "B) What does the measure capture? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-settle",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-subject",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2.3 (4 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "Provide an implementation of purity. Recall that purity is the weighted sum of the individual $purity_i = \\frac{1}{|C_i|} \\max_{j=1..k}\\{n_{ij}\\}$ values where $n_{ij}$ is the number of common points in cluster $C_i$\n",
    "and ground-truth cluster $j$ obtained from the labels $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "T = np.array([]) # Ground-truth clusters\n",
    "C = np.array([]) # Clusters obtained by k-means\n",
    "### YOUR CODE HERE\n",
    "\n",
    "## C is the clustering from k-means and T is the ground truth cluster assignments.\n",
    "def purity(C, T):\n",
    "    purity = 0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return purity\n",
    "\n",
    "print('Purity: {}, CE: {}'.format(purity(C,T), CE(C,T)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "phantom-reform",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2.4 (2 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "\n",
    "Print the purity of the clusters obtained by k-means in Task 3.1.1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = df[df['A'].isin(['Universal', 'Intelligence'])]\n",
    "first = \"T+\"\n",
    "second = \"INT+\"\n",
    "X = toy[[first, second]].to_numpy()\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-sector",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Compare purity with **Conditional Entropy (CE)**. Which measure is preferable? (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "- [ ] **CE** is preferable because it uses all the points\n",
    "- [ ] Purity is preferable because it is less computational demanding\n",
    "- [ ] **CE** is preferrable because it does not favor small clusters\n",
    "- [ ] Purity is preferrable because it tends to favor balanced clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-influence",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "generic-state",
   "metadata": {},
   "source": [
    "## Task 3.3 Gaussian Mixtures and the EM-Algorithm\n",
    "### Task 3.3.1 (6 point)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> the EM-algorithm for the Gaussian Mixture Model.\n",
    "<br> You can consult [DMA] Section 13.3.2, for a description of how the algorithm works in this particular setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.gmm import GMM\n",
    "class MyGMM(GMM):\n",
    "    def initialize_parameters(self, X):\n",
    "        \"\"\"\n",
    "            This function should utilize information from the data to initialize\n",
    "            the parameters of the model.\n",
    "            In particular, it should compute initial values for mu, Sigma, and pi.\n",
    "            \n",
    "            The function corresponds to line 2-4 in Algorithm 13.3 in [DMA, p. 349]\n",
    "            Note, that K can be retrieved as `self.K`.\n",
    "\n",
    "            Args:\n",
    "                X (matrix, [n, d]): Data to be used for initialization.\n",
    "\n",
    "            Returns:\n",
    "                Tuple (mu, Sigma, pi), \n",
    "                    mu has size        [K, d]\n",
    "                    Sigma has size     [K, d, d]\n",
    "                    pi has size        [K]\n",
    "        \"\"\"\n",
    "        # TODO: what should the values be for initializing mu, Sigma and pi\n",
    "        return mu, Sigma, pi\n",
    "\n",
    "\n",
    "    def posterior(self, X):\n",
    "        \"\"\"\n",
    "            The E-step of the EM algorithm. \n",
    "            Returns the posterior probability p(Y|X)\n",
    "\n",
    "            This function corresponds to line 8 in Algorithm 13.3 in [DMA, p. 349]\n",
    "            Note, that mean and covariance matrices can be accessed by `self.mu` and `self.Sigma`, respectively.\n",
    "            \n",
    "            Args:\n",
    "                X (matrix, [n,  d]): Data to compute posterior for.\n",
    "\n",
    "            Returns:\n",
    "                Matrix of size        [n, K]\n",
    "        \"\"\"\n",
    "        # TODO: what is the posterior probability?\n",
    "        \n",
    "        return posterior\n",
    "        \n",
    "\n",
    "    def m_step(self, X, P):\n",
    "        \"\"\"\n",
    "            Update the estimates of mu, Sigma, and pi, given the data `X` and the current\n",
    "            posterior probabilities `P`.\n",
    "\n",
    "            This function corresponds to line 10-12 in Algorithm 13.3 and Eqn. (13.11-13) in [DMA, p. 349].\n",
    "            \n",
    "            Args:\n",
    "                X (matrix, [n, d]): Data matrix\n",
    "                P (matrix, [n, K]): The posterior probabilities for the n samples.\n",
    "\n",
    "            Returns:\n",
    "                Tuple (mu, Sigma, pi), \n",
    "                    mu has size        [K, d]\n",
    "                    Sigma has size    [K, d, d]\n",
    "                    pi has size        [K]\n",
    "        \"\"\"\n",
    "        # TODO: what is the values of mu, Sigma, and pi that maximizes the expectation given the posterior?\n",
    "        return  mu_hat, Si_hat, pi_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-wireless",
   "metadata": {},
   "source": [
    "### Task 3.3.2 (2 points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "A) Run your EM-algorithm for GaussianMixtures<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = df[df['A'].isin(['Intelligence', 'Strength'])]\n",
    "first = \"T+\"\n",
    "second = \"STR+\"\n",
    "\n",
    "labels = toy[['A']].to_numpy()\n",
    "labels = np.unique(labels, return_inverse=True)[1]\n",
    "X = toy[[first, second]].to_numpy()\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)\n",
    "\n",
    "\n",
    "clusters = None\n",
    "plt.scatter(X_norm[:, 0], X_norm[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60e5df",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "B) What are the advantages and disadvantages of this approach?<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8058f8",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-culture",
   "metadata": {},
   "source": [
    "# Part 4 Outlier detection\n",
    "In this exercise we will work with outlier detection techniques and analyze their performance on the small dataset. Before starting the exercise, run the code below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = df[df['A'].isin(['Intelligence', 'Strength'])]\n",
    "first = \"T+\"\n",
    "second = \"STR+\"\n",
    "X = toy[[first, second]].to_numpy()\n",
    "\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-mumbai",
   "metadata": {},
   "source": [
    "## Task 4.1 (DBoutliers)\n",
    "We will now compare two outlier detection techniques.\n",
    "### Task 4.1.1 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a simple distance-based outlier detector. This is the distance-based outlier detection from the lectures, where a point is considered an outlier if at most a fraction $pi$ of the other points have a distance less of than $eps$ to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBOutliers(X, eps, pi): \n",
    "    outliers = None\n",
    "    ### YOUR STARTS CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-somewhere",
   "metadata": {},
   "source": [
    "### Task 4.1.2 (2 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span>\n",
    "DBOutliers requires tuning the parameters eps, pi. Run the code from Task 4.1.1 with different choices of eps, pi \n",
    "\n",
    "**Note** that the data is normalized. Choose two ranges with **at least** 4 values each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-simulation",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "**Present** the results  and **discuss** how the results vary with respect to (1) eps and (2) pi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-stanford",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-reset",
   "metadata": {},
   "source": [
    "### Task 4.1.3 (3 points)\n",
    "**NOTE** This is hard but also fun. Since it is not impacting the grade too much, you can choose to invent something new.\n",
    "\n",
    "A) Propose and <span style='color: green'>**\\[Implement\\]**</span> a heuristic method to tune parameters eps, pi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_dboutliers(X): \n",
    "    eps = 0\n",
    "    pi = 0\n",
    "    ### YOUR STARTS CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR ENDS CODE HERE\n",
    "    return eps, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-threshold",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> your algorithm, its main idea, its strengths and its weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-progressive",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-hanging",
   "metadata": {},
   "source": [
    "## Task 4.2 LOF (2 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "Using the parameters eps=0.18, pi=0.2 compare the results of DBOutliers with those obtained by LOF implemented in Week 9. What outliers do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-faith",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
